# AUTOGENERATED! DO NOT EDIT! File to edit: nbs/team-strength.ipynb (unless otherwise specified).

__all__ = ['ModelABC', 'Benchmark', 'DCGoals', 'DCxG', 'DCEnsemble', 'DCxGTotals', 'DCNonShotxG', 'DCRhoTransplant',
           'eps_values', 'MODEL_REGISTRY']

# Cell
import abc
import collections
import datetime as dt
import functools
import itertools

import mezzala
import numpy as np
import scipy.stats

import wingback.db

# Cell


class ModelABC:
    @abc.abstractmethod
    def fetch_data(self, league_ids, date):
        training_data = ...  # e.g. matches up-to, not including `date`
        return training_data

    @abc.abstractmethod
    def fit(self, data):
        return self

    @abc.abstractmethod
    def predict(self, data):
        predictions = ...
        return predictions

    @abc.abstractmethod
    def to_dict(self):
        return ...

# Cell


class Benchmark(ModelABC):
    """
    A benchmark model that gives the same predictions for every match.

    This prediction is simply an average of the observed scoreline frequency
    within the training data.
    """

    def __init__(self, time_window=360):
        self._time_window = time_window

        self._data = None

    @property
    def time_window(self):
        return dt.timedelta(days=self._time_window)

    def fetch_data(self, league_ids, date):
        training_data = wingback.db.queries.fetch_matches(
            start=date-self.time_window,
            end=date,
            league_ids=league_ids,
            season_ids=[None]
        )

        return list(training_data)

    def fit(self, data):
        counts = collections.Counter((x['home_goals'], x['away_goals']) for x in data)
        self._data = [
            mezzala.ScorelinePrediction(
                home_goals=hg,
                away_goals=ag,
                probability=count/len(data)
            )
            for (hg, ag), count in counts.items()
        ]
        return self

    def predict(self, data):
        # Just make the same prediction for every match
        return [self._data]*len(data)

    def to_dict(self):
        return {
            'time_window': self._time_window
        }

# Internal Cell


def encode_parameter_key(key):
    if isinstance(key, mezzala.OffenceParameterKey):
        return ('Offence', key.label)
    if isinstance(key, mezzala.DefenceParameterKey):
        return ('Defence', key.label)
    if isinstance(key, mezzala.ParameterKey):
        return key.label
    return key


def decode_parameter_key(key):
    if isinstance(key, str):
        return mezzala.ParameterKey(key)
    if isinstance(key, list):
        off_def, label = key
        if off_def == 'Offence':
            return mezzala.OffenceParameterKey(label)
        if off_def == 'Defence':
            return mezzala.DefenceParameterKey(label)

# Internal Cell


def init_model(weight, params=None):
    base_adapter = mezzala.KeyAdapter(
        home_goals='home_goals',
        away_goals='away_goals',
        home_team='home_team_id',  # Might be nicer to do a tuple of (ID, name)?
        away_team='away_team_id',
    )
    model = mezzala.DixonColes(
        adapter=mezzala.LumpedAdapter(
            base_adapter,
            home_team=('Other team', 5),
            away_team=('Other team', 5),
        ),
        blocks=[
            mezzala.blocks.BaseRate(),
            mezzala.blocks.TeamStrength(),
            mezzala.blocks.HomeAdvantage(),
            mezzala.blocks.ConstantBlock(
                mezzala.OffenceParameterKey('Other team'),
                mezzala.DefenceParameterKey('Other team')
            ),
        ],
        weight=weight,
        params=params
    )

    return model

# Cell


class DCGoals(ModelABC):
    def __init__(self, time_window=360, epsilon=-0.0065, params=None):
        self._time_window = time_window
        self._epsilon = epsilon

        # Create the model
        self._model = init_model(
            weight=mezzala.weights.ExponentialWeight(
                epsilon=epsilon,
                key=lambda x: x['days_ago']
            ),
            params=params
        )

    @property
    def time_window(self):
        return dt.timedelta(days=self._time_window)

    def fetch_data(self, league_ids, date):
        training_data = wingback.db.queries.fetch_matches(
            start=date-self.time_window,
            end=date,
            league_ids=league_ids,
            season_ids=[None]
        )

        return list(training_data)

    def fit(self, data):
        self._model.adapter.fit(data)
        self._model.fit(data)
        return self

    def predict(self, data):
        predictions = self._model.predict(data)
        return predictions

    def to_dict(self):
        return {
            'time_window': self._time_window,
            'epsilon': self._epsilon,
            'params': [
                (encode_parameter_key(k), v if not np.isnan(v) else None)
                for k, v in self._model.params.items()
            ]
        }

# Cell


class DCxG(ModelABC):
    def __init__(self, min_probability=0.01, time_window=360, epsilon=-0.0065, params=None):
        self._time_window = time_window
        self._epsilon = epsilon
        self.min_probability = min_probability

        self._model = init_model(
            weight=mezzala.weights.KeyWeight(
                lambda x: x['probability']*np.exp(self._epsilon*x['days_ago'])
            ),
            params=params
        )

    @property
    def time_window(self):
        return dt.timedelta(days=self._time_window)

    def fetch_data(self, league_ids, date):
        training_matches = list(wingback.db.queries.fetch_matches(
            start=date-self.time_window,
            end=date,
            league_ids=league_ids,
            season_ids=[None]
        ))
        training_resimulations = list(wingback.db.queries.fetch_resimulations(
            match_ids=[m['id'] for m in training_matches],
            min_probability=self.min_probability
        ))

        # Merge matches and training data
        training_data = []
        for match in training_matches:
            training_data += [
                {**match, **t}
                for t in training_resimulations
                if t['match_id'] == match['id']
            ]

        # We return both the match data and the resim data because
        # we want to fit the adapter on the *match data* while fitting
        # the actual model on the xG resims
        return (list(training_matches), list(training_data))

    def fit(self, data):
        match_data, resim_data = data

        # Fit the adapter using the actual number of matches
        #Â (as opposed to the number of resimulations present...)
        self._model.adapter.fit(match_data)

        # And fit the model parameters on the xG resimulations
        self._model.fit(resim_data)

        return self

    def predict(self, data):
        predictions = self._model.predict(data)
        return predictions

    def to_dict(self):
        return {
            'time_window': self._time_window,
            'min_probability': self.min_probability,
            'epsilon': self._epsilon,
            'params': [
                (encode_parameter_key(k), v if not np.isnan(v) else None)
                for k, v in self._model.params.items()
            ]
        }

# Cell


class DCEnsemble(ModelABC):
    def __init__(self, models=[], time_window=360):
        self.models = models
        self._time_window = time_window

        # Weight is irrelevant since _model.fit
        # is never actually called
        self._model = init_model(weight=lambda x: 1)

    @property
    def time_window(self):
        return dt.timedelta(days=self._time_window)

    @staticmethod
    def _fetch_backtest_params(model, league_ids, date):
        backtest = wingback.db.queries.fetch_backtest(
            model=model,
            date=date,
            league_ids=league_ids
        )
        params = backtest['json']['parameters']['params']
        return {decode_parameter_key(k): v for k, v in params}

    def fetch_data(self, league_ids, date):
        # Fetch models from database
        model_params = {
            (model, weight): self._fetch_backtest_params(model, league_ids, date)
            for model, weight in self.models
        }

        # We also need to fetch the "regular" data to fit the lumped adapter
        training_data = wingback.db.queries.fetch_matches(
            start=date-self.time_window,
            end=date,
            league_ids=league_ids,
            season_ids=[None]
        )

        return (model_params, list(training_data))

    def fit(self, data):
        model_params, match_data = data

        # Reduce parameter values

        # First, we need to get all the parameters used by the models in question
        # We take the intersection of each models' parameters. Although, since each
        # model should have exactly the same parameters, it shouldn't matter whether
        # we take the intersection or superset of all parameters
        # NOTE: is there a nice, pythonic way to transpose list-of-maps into map-of-lists?
        # NB: The data is a dict of {model_name: params}
        param_keys = functools.reduce(
            # Find the intersection of each models' parameters
            lambda x, y: x & y,
            [set(params.keys()) for params in model_params.values()]
        )

        # To actually combine the parameters, we just take a weighted average
        # of the parameter values in real space (they are stored internally in
        # log space)
        params = {}
        for k in param_keys:
            param = np.average(
                # Shift parameters back from log-space into real values
                np.exp([p[k] for p in model_params.values()]),
                # Use weights for *weighted* average
                weights=[w for _, w in model_params.keys()]
            )

            # Finally, move parameter back into log-space
            params[k] = np.log(param)

        # Insert params into the model
        self._model.params = params

        # We also need to fit the lumped adapter
        self._model.adapter.fit(match_data)
        return self

    def predict(self, data):
        predictions = self._model.predict(data)
        return predictions

    def to_dict(self):
        return {
            'models': self.models,
            'params': [
                (encode_parameter_key(k), v if not np.isnan(v) else None)
                for k, v in self._model.params.items()
            ]
        }

# Cell


def _gen_poisson_simulations(home_rate, away_rate, up_to=26, min_probability=0.01):
    home_goals = [(i, scipy.stats.poisson.pmf(i, home_rate)) for i in range(up_to)]
    away_goals = [(i, scipy.stats.poisson.pmf(i, away_rate)) for i in range(up_to)]
    for (hg, hp), (ag, ap) in itertools.product(home_goals, away_goals):
        probability = hp*ap

        if probability <= min_probability:
            continue

        yield {
            'home_goals': hg,
            'away_goals': ag,
            'probability': probability
        }


class DCxGTotals(ModelABC):
    def __init__(self, min_probability=0.01, time_window=360, epsilon=-0.0065, params=None):
        self._time_window = time_window
        self._epsilon = epsilon
        self.min_probability = min_probability

        self._model = init_model(
            weight=mezzala.weights.KeyWeight(
                lambda x: x['probability']*np.exp(self._epsilon*x['days_ago'])
            ),
            params=params
        )

    @property
    def time_window(self):
        return dt.timedelta(days=self._time_window)


    def fetch_data(self, league_ids, date):
        training_matches = list(wingback.db.queries.fetch_matches(
            start=date-self.time_window,
            end=date,
            league_ids=league_ids,
            season_ids=[None]
        ))

        # Create Poisson training data from match xG totals
        # NOTE: initially, I tried using understat's own `home_xg` and
        # `away_xg` fields. However, these bunch shots from the same
        # possession together. While this is a fine choice, I didn't
        # do this for the DCxG model's inputs. So to keep the comparison
        # fair, I'll use the *total* match xGs (calculated in dbt,
        # returned in the matches query)
        training_data = []
        for match in training_matches:
            training_data += [
                {**match, **t} for
                t in _gen_poisson_simulations(match['naive_home_xg'], match['naive_away_xg'], min_probability=self.min_probability)
            ]

        # We return both the match data and the resim data because
        # we want to fit the adapter on the *match data* while fitting
        # the actual model on the xG-poisson sims
        return (list(training_matches), list(training_data))

    def fit(self, data):
        match_data, resim_data = data

        # Fit the adapter using the actual number of matches
        # (as opposed to the number of resimulations present...)
        self._model.adapter.fit(match_data)

        # And fit the model parameters on the xG resimulations
        self._model.fit(resim_data)

        return self

    def predict(self, data):
        predictions = self._model.predict(data)
        return predictions

    def to_dict(self):
        return {
            'time_window': self._time_window,
            'min_probability': self.min_probability,
            'epsilon': self._epsilon,
            'params': [
                (encode_parameter_key(k), v if not np.isnan(v) else None)
                for k, v in self._model.params.items()
            ]
        }

# Cell


class DCNonShotxG(ModelABC):
    def __init__(self, min_probability=0.01, time_window=360, epsilon=-0.0065, params=None):
        self._time_window = time_window
        self._epsilon = epsilon
        self.min_probability = min_probability

        self._model = init_model(
            weight=mezzala.weights.KeyWeight(
                lambda x: x['probability']*np.exp(self._epsilon*x['days_ago'])
            ),
            params=params
        )

    @property
    def time_window(self):
        return dt.timedelta(days=self._time_window)


    def fetch_data(self, league_ids, date):
        training_matches = list(wingback.db.queries.fetch_matches(
            start=date-self.time_window,
            end=date,
            league_ids=league_ids,
            season_ids=[None]
        ))

        # Create Poisson training data from 538's ns-xG totals
        training_data = []
        for match in training_matches:

            # Skip matches where nsxg is missing
            if match['home_nsxg'] is None:
                continue

            training_data += [
                {**match, **t} for
                t in _gen_poisson_simulations(match['home_nsxg'], match['away_nsxg'], min_probability=self.min_probability)
            ]

        # We return both the match data and the resim data because
        # we want to fit the adapter on the *match data* while fitting
        # the actual model on the xG-poisson sims
        return (list(training_matches), list(training_data))

    def fit(self, data):
        match_data, resim_data = data

        self._model.adapter.fit(match_data)
        self._model.fit(resim_data)

        return self

    def predict(self, data):
        predictions = self._model.predict(data)
        return predictions

    def to_dict(self):
        return {
            'time_window': self._time_window,
            'min_probability': self.min_probability,
            'epsilon': self._epsilon,
            'params': [
                (encode_parameter_key(k), v if not np.isnan(v) else None)
                for k, v in self._model.params.items()
            ]
        }

# Cell


class DCRhoTransplant(ModelABC):
    def __init__(self, primary_model, rho_model, time_window=360):
        self.primary_model = primary_model
        self.rho_model = rho_model
        self._time_window = time_window

        # Weight is irrelevant since _model.fit
        # is never actually called
        self._model = init_model(weight=lambda x: 1)

    @property
    def time_window(self):
        return dt.timedelta(days=self._time_window)

    @staticmethod
    def _fetch_backtest_params(model, league_ids, date):
        backtest = wingback.db.queries.fetch_backtest(
            model=model,
            date=date,
            league_ids=league_ids
        )
        params = backtest['json']['parameters']['params']
        return {decode_parameter_key(k): v for k, v in params}

    def fetch_data(self, league_ids, date):
        # Fetch models from database
        model_params = {
            model: self._fetch_backtest_params(model, league_ids, date)
            for model in [self.primary_model, self.rho_model]
        }

        # We also need to fetch the "regular" data to fit the lumped adapter
        training_data = wingback.db.queries.fetch_matches(
            start=date-self.time_window,
            end=date,
            league_ids=league_ids,
            season_ids=[None]
        )

        return (model_params, list(training_data))

    def fit(self, data):
        model_params, match_data = data

        # Insert params into the model
        model_params[self.primary_model][mezzala.RHO_KEY] = model_params[self.rho_model][mezzala.RHO_KEY]
        self._model.params = model_params[self.primary_model]

        # We also need to fit the lumped adapter
        self._model.adapter.fit(match_data)
        return self

    def predict(self, data):
        predictions = self._model.predict(data)
        return predictions

    def to_dict(self):
        return {
            'primary_model': self.primary_model,
            'rho_model': self.rho_model,
            'params': [
                (encode_parameter_key(k), float(v) if not np.isnan(v) else None)
                for k, v in self._model.params.items()
            ]
        }

# Cell
eps_values = np.log(np.linspace(0.05, 0.95, 8))/365
eps_values

# Cell

MODEL_REGISTRY = {}


MODEL_REGISTRY['benchmark'] = Benchmark(time_window=730)

for eps in eps_values:
    MODEL_REGISTRY[f'dixon-coles{eps:0.6f}'] = DCGoals(time_window=730, epsilon=eps)
    MODEL_REGISTRY[f'dixon-coles-xg{eps:0.6f}'] = DCxG(time_window=730, epsilon=eps, min_probability=0.01)
    MODEL_REGISTRY[f'dixon-coles-ns-xg{eps:0.6f}'] = DCNonShotxG(time_window=730, epsilon=eps, min_probability=0.01)

for xg_mix in np.linspace(0.05, 0.95, 8):
    MODEL_REGISTRY[f'ensemble-{xg_mix:0.5f}'] = DCEnsemble(
        [('dixon-coles-0.001568', 1-xg_mix),
         ('dixon-coles-xg-0.003234', xg_mix)],
        time_window=730
    )

MODEL_REGISTRY['dixon-coles-xg-totals-0.003234'] = DCxGTotals(time_window=730, epsilon=-0.003234)

MODEL_REGISTRY['dixon-coles-xg-rho-transplant'] = DCRhoTransplant(
    primary_model='dixon-coles-xg-0.003234',
    rho_model='dixon-coles-0.001568',
)